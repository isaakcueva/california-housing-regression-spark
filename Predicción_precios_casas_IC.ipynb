{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Tarea: Predicción precios casas - Regresión Lineal con Regularización\n",
        "\n",
        "# Nombre: Isaac Cueva\n",
        "\n",
        "# Fecha: 17/05/2025"
      ],
      "metadata": {
        "id": "KQ_1QjN4B3rT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Descripción de la imagen](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRP9d63jC144Usqa_NjecnoWcJXV60JuFTJLA&s)"
      ],
      "metadata": {
        "id": "-Do0OrzPCJDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Inciar una Sesión de Spark"
      ],
      "metadata": {
        "id": "X-wQzkwKCMnE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJFkj9NBBusp",
        "outputId": "dd13543c-b3aa-40df-8cef-b3a51bbbde8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "# Installing required packages\n",
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PySpark is the Spark API for Python. In this lab, we use PySpark to initialize the spark context.\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "# Provides findspark.init() to make pyspark importable as a regular library.\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "-fSnp5KlCRjK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a spark context class\n",
        "sc = SparkContext()\n",
        "\n",
        "# Creating a spark session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Regresión Lineal\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "gdTKbtn9CXfn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Hs2zt2J6CX-Q",
        "outputId": "595389e6-b662-44f3-ee95-b9620b9c4fdd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2a7006d2d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://00a56b2bdc21:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TAREAS"
      ],
      "metadata": {
        "id": "oGQXz5mYCapp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el dataset adjunto, genere un modelo de regresión lineal regularizado que permita predecir el valor de la mediana de una casa en California.\n",
        "\n",
        "Las variables que están en el dataset son:\n",
        "\n",
        "1. longitude (signed numeric - float) : Valor de longitud para el bloque en California, EE. UU.\n",
        "2. latitude (numeric - float ) : Valor de latitud para el bloque en California, EE. UU.\n",
        "3. housing_median_age (numeric - int ) : Edad media de la casa en el bloque\n",
        "4. total_rooms (numeric - int ) : Recuento del número total de habitaciones (excluidos los dormitorios) en todas las casas del bloque\n",
        "5. total_bedrooms (numeric - float ) : Recuento del número total de dormitorios en todas las casas del bloque\n",
        "6. population (numeric - int ) : Recuento del número total de población en el bloque\n",
        "7. households (numeric - int ) : Recuento del número total de hogares en el bloque\n",
        "8. median_income (numeric - float ) : Mediana del ingreso total del hogar de todas las casas del bloque\n",
        "9. ocean_proximity (numeric - categórico ) : Tipo de paisaje del bloque [ Valores únicos : 'CERCA DE LA BAHÍA', '<1H OCEAN', 'INTERIOR', 'CERCA DEL OCÉANO', 'ISLA' ]\n",
        "10. median_house_value (numeric - int ) : Mediana de los precios de las viviendas de todas las casas del bloque"
      ],
      "metadata": {
        "id": "TTM56sSnCfYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actividades a realizar:\n",
        "\n",
        "1. Solvente cualquier problema que exista con datos faltantes."
      ],
      "metadata": {
        "id": "NhWOHCxeC1zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = \"1553768847-housing.csv\"\n",
        "\n",
        "# Cargar CSV en Spark DataFrame\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Mostrar esquema para validar la carga\n",
        "df.printSchema()\n",
        "\n",
        "# Mostrar primeras filas para inspección\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75vxYlPYCa6n",
        "outputId": "f72b4bce-3621-4410-d4b2-c3f1f8dcea15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: integer (nullable = true)\n",
            " |-- total_rooms: integer (nullable = true)\n",
            " |-- total_bedrooms: integer (nullable = true)\n",
            " |-- population: integer (nullable = true)\n",
            " |-- households: integer (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- ocean_proximity: string (nullable = true)\n",
            " |-- median_house_value: integer (nullable = true)\n",
            "\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+---------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|ocean_proximity|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+---------------+------------------+\n",
            "|  -122.23|   37.88|                41|        880|           129|       322|       126|       8.3252|       NEAR BAY|            452600|\n",
            "|  -122.22|   37.86|                21|       7099|          1106|      2401|      1138|       8.3014|       NEAR BAY|            358500|\n",
            "|  -122.24|   37.85|                52|       1467|           190|       496|       177|       7.2574|       NEAR BAY|            352100|\n",
            "|  -122.25|   37.85|                52|       1274|           235|       558|       219|       5.6431|       NEAR BAY|            341300|\n",
            "|  -122.25|   37.85|                52|       1627|           280|       565|       259|       3.8462|       NEAR BAY|            342200|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+---------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, sum, when\n",
        "\n",
        "# Contar valores nulos por columna\n",
        "df.select([sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in df.columns]).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY8f-UTGDa4E",
        "outputId": "dad70ea3-f85d-44d6-a46a-f57c95781bd8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+---------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|ocean_proximity|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+---------------+------------------+\n",
            "|        0|       0|                 0|          0|           207|         0|         0|            0|              0|                 0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+---------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Corregir los nulos con la Mediana"
      ],
      "metadata": {
        "id": "K349ENNYFgHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit\n",
        "\n",
        "# Calcular la mediana\n",
        "mediana = df.approxQuantile(\"total_bedrooms\", [0.5], 0.01)[0]\n",
        "\n",
        "# Imputar valores nulos con la mediana\n",
        "df = df.na.fill({\"total_bedrooms\": mediana})\n",
        "\n",
        "# Verificar que ya no haya nulos en total_bedrooms\n",
        "df.select(sum(when(col(\"total_bedrooms\").isNull(), 1).otherwise(0)).alias(\"nulos_total_bedrooms\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S669pKPDbba",
        "outputId": "9e5cf5db-993d-441e-e616-fe4c16fa4e37"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|nulos_total_bedrooms|\n",
            "+--------------------+\n",
            "|                   0|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Transforme las variables categóricas en variables tipo dummy."
      ],
      "metadata": {
        "id": "g6ukEZrTF0rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# StringIndexer para la columna categórica\n",
        "indexer = StringIndexer(inputCol=\"ocean_proximity\", outputCol=\"ocean_proximity_index\")\n",
        "\n",
        "# OneHotEncoder para transformar índices en variables dummy\n",
        "encoder = OneHotEncoder(inputCols=[\"ocean_proximity_index\"], outputCols=[\"ocean_proximity_vec\"])\n",
        "\n",
        "# Crear pipeline para encadenar ambos pasos\n",
        "pipeline = Pipeline(stages=[indexer, encoder])\n",
        "\n",
        "# Ajustar y transformar el DataFrame\n",
        "df_encoded = pipeline.fit(df).transform(df)\n",
        "\n",
        "# Mostrar resultado con las nuevas columnas\n",
        "df_encoded.select(\"ocean_proximity\", \"ocean_proximity_index\", \"ocean_proximity_vec\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BC8Da_aEPE7",
        "outputId": "f30e953e-9a0b-4c6f-a3cb-aaca6bb7cc94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---------------------+-------------------+\n",
            "|ocean_proximity|ocean_proximity_index|ocean_proximity_vec|\n",
            "+---------------+---------------------+-------------------+\n",
            "|NEAR BAY       |3.0                  |(4,[3],[1.0])      |\n",
            "|NEAR BAY       |3.0                  |(4,[3],[1.0])      |\n",
            "|NEAR BAY       |3.0                  |(4,[3],[1.0])      |\n",
            "|NEAR BAY       |3.0                  |(4,[3],[1.0])      |\n",
            "|NEAR BAY       |3.0                  |(4,[3],[1.0])      |\n",
            "+---------------+---------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Construir vector de características"
      ],
      "metadata": {
        "id": "NOv88OcSGPbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Lista columnas numéricas (excluyendo median_house_value)\n",
        "numeric_cols = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\",\n",
        "                \"population\", \"households\", \"median_income\"]\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_cols + [\"ocean_proximity_vec\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Crear nuevo DataFrame con columna features y columna label para la variable objetivo\n",
        "df_final = assembler.transform(df_encoded).select(\"features\", col(\"median_house_value\").alias(\"label\"))\n",
        "\n",
        "# Mostrar ejemplo\n",
        "df_final.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FgqNtiLGRe1",
        "outputId": "488ed782-379f-4a4b-a5a0-3afa235dfa8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------+------+\n",
            "|features                                                               |label |\n",
            "+-----------------------------------------------------------------------+------+\n",
            "|[-122.23,37.88,41.0,880.0,129.0,322.0,126.0,8.3252,0.0,0.0,0.0,1.0]    |452600|\n",
            "|[-122.22,37.86,21.0,7099.0,1106.0,2401.0,1138.0,8.3014,0.0,0.0,0.0,1.0]|358500|\n",
            "|[-122.24,37.85,52.0,1467.0,190.0,496.0,177.0,7.2574,0.0,0.0,0.0,1.0]   |352100|\n",
            "|[-122.25,37.85,52.0,1274.0,235.0,558.0,219.0,5.6431,0.0,0.0,0.0,1.0]   |341300|\n",
            "|[-122.25,37.85,52.0,1627.0,280.0,565.0,259.0,3.8462,0.0,0.0,0.0,1.0]   |342200|\n",
            "+-----------------------------------------------------------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Divida el dataset en datos de entrenamiento y datos de evaluación."
      ],
      "metadata": {
        "id": "JY07hKikGdma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = df_final.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"Tamaño de entrenamiento: {train_df.count()}\")\n",
        "print(f\"Tamaño de evaluación: {test_df.count()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdij5gajGSAi",
        "outputId": "843d9f6c-0f4c-42ed-9ad4-dab34e3ba3e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de entrenamiento: 16560\n",
            "Tamaño de evaluación: 4080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Genere un modelo de regresión multivariable para predecir la mediana de los precios de las casas.\n",
        "Evalúe su modelo con el MSE y el valor de R^2,"
      ],
      "metadata": {
        "id": "6r-ibHUXGjv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Crear el modelo de regresión lineal sin regularización\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\", regParam=0.0, elasticNetParam=0.0)\n",
        "\n",
        "# Entrenar el modelo\n",
        "lr_model = lr.fit(train_df)\n",
        "\n",
        "# Predecir en el conjunto de test\n",
        "predictions = lr_model.transform(test_df)\n",
        "\n",
        "# Evaluadores para MSE y R^2\n",
        "evaluator_mse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mse\")\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "# Calcular métricas\n",
        "mse = evaluator_mse.evaluate(predictions)\n",
        "r2 = evaluator_r2.evaluate(predictions)\n",
        "\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"R²: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxTUrItdGadc",
        "outputId": "dd8a5f59-920f-4677-a7e0-f38cf27e6797"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 5010754518.012139\n",
            "R²: 0.6378429926191952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Genere un modelo de regresión multivariable de grado 2 para predecir la mediana de los precios de las casas.\n",
        "Evalúe su modelo con el MSE y el valor de R^2."
      ],
      "metadata": {
        "id": "xPPDDwdlHBgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import PolynomialExpansion\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "# Expansor polinómico grado 2\n",
        "polyExpansion = PolynomialExpansion(degree=2, inputCol=\"features\", outputCol=\"polyFeatures\")\n",
        "\n",
        "# Transformar conjuntos de entrenamiento y prueba\n",
        "train_poly = polyExpansion.transform(train_df)\n",
        "test_poly = polyExpansion.transform(test_df)\n",
        "\n",
        "# Modelo de regresión lineal con features polinómicas\n",
        "lr_poly = LinearRegression(featuresCol=\"polyFeatures\", labelCol=\"label\", regParam=0.0, elasticNetParam=0.0)\n",
        "\n",
        "# Entrenar modelo\n",
        "lr_poly_model = lr_poly.fit(train_poly)\n",
        "\n",
        "# Predecir en test\n",
        "predictions_poly = lr_poly_model.transform(test_poly)\n",
        "\n",
        "# Evaluar métricas\n",
        "mse_poly = evaluator_mse.evaluate(predictions_poly)\n",
        "r2_poly = evaluator_r2.evaluate(predictions_poly)\n",
        "\n",
        "print(f\"MSE Modelo Polinómico grado 2: {mse_poly}\")\n",
        "print(f\"R² Modelo Polinómico grado 2: {r2_poly}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9FvYOnIG63v",
        "outputId": "285d0d61-1155-449f-f009-860fa0baf887"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Modelo Polinómico grado 2: 21057602127.419735\n",
            "R² Modelo Polinómico grado 2: -0.521958048766564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El resultado indica que el modelo está funcionando peor que una simple predicción basada en la media del valor objetivo. La expansión polinómica genera una cantidad muy grande de variables, lo que provoca sobreajuste y alta complejidad. Además, con muchas variables y sin una adecuada selección o regularización, el modelo se vuelve inestable y no generaliza bien."
      ],
      "metadata": {
        "id": "vUOgM4yFIjhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Seleccione el mejor modelo y aplique regularización: genere un modelo de regesión Lasso.\n",
        "Evalúe su modelo con el MSE y el valor de R^2."
      ],
      "metadata": {
        "id": "UbnW9YktI9mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "# Modelo Lasso (elasticNetParam=1)\n",
        "lasso = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"label\", regParam=0.1, elasticNetParam=1.0)\n",
        "\n",
        "# Entrenar modelo Lasso con datos escalados de entrenamiento\n",
        "lasso_model = lasso.fit(train_scaled)\n",
        "\n",
        "# Predecir en datos de test escalados\n",
        "predictions_lasso = lasso_model.transform(test_scaled)\n",
        "\n",
        "# Evaluar con MSE y R2\n",
        "mse_lasso = evaluator_mse.evaluate(predictions_lasso)\n",
        "r2_lasso = evaluator_r2.evaluate(predictions_lasso)\n",
        "\n",
        "print(f\"MSE Modelo Lasso: {mse_lasso}\")\n",
        "print(f\"R² Modelo Lasso: {r2_lasso}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J691-YOHIMxg",
        "outputId": "7a2533f1-5e5c-4828-f5e9-a431c057c07d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Modelo Lasso: 5153100102.186113\n",
            "R² Modelo Lasso: 0.6275548313067607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Aplique nuevamente regularización al mejor modelo: genere un modelo de regresión Ridge.\n",
        "Evalúe su modelo con el MSE y el valor de R^2."
      ],
      "metadata": {
        "id": "ZMgwF4V3JlNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo Ridge (elasticNetParam=0)\n",
        "ridge = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"label\", regParam=0.1, elasticNetParam=0.0)\n",
        "\n",
        "# Entrenar modelo Ridge\n",
        "ridge_model = ridge.fit(train_scaled)\n",
        "\n",
        "# Predecir en test\n",
        "predictions_ridge = ridge_model.transform(test_scaled)\n",
        "\n",
        "# Evaluar\n",
        "mse_ridge = evaluator_mse.evaluate(predictions_ridge)\n",
        "r2_ridge = evaluator_r2.evaluate(predictions_ridge)\n",
        "\n",
        "print(f\"MSE Modelo Ridge: {mse_ridge}\")\n",
        "print(f\"R² Modelo Ridge: {r2_ridge}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvSH-iBoJIhl",
        "outputId": "8d0de8ea-6650-49f3-d070-7a97b06b4d8e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Modelo Ridge: 5154029304.250958\n",
            "R² Modelo Ridge: 0.6274876723513885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Concluya cual de los tres modelos (modelo normal y los dos con regularización), es el mejor modelo y porqué."
      ],
      "metadata": {
        "id": "XgzmO-qaKNVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Modelo                     | MSE              | R²            |\n",
        "|----------------------------|------------------|---------------|\n",
        "| Regresión Lineal Simple     | 5,010,754,518.01 | 0.6378        |\n",
        "| Regresión Lineal con Lasso  | 5,153,100,102.19 | 0.6276        |\n",
        "| Regresión Lineal con Ridge  | 5,154,029,304.25 | 0.6275        |\n"
      ],
      "metadata": {
        "id": "4lreUam5KZNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque el modelo lineal simple obtuvo un ajuste ligeramente mejor en términos de MSE y R², los modelos con regularización de Lasso y Ridge presentan una mayor robustez y capacidad de generalización gracias a la penalización aplicada. Entre estos, Lasso es preferible si se busca un modelo más simple y con selección automática de variables, mientras que Ridge es útil para mantener todas las variables con coeficientes regularizados. A mi criterio, concluyo que el mejor es Lasso por su balance entre desempeño y simplicidad, lo que facilita la interpretación y evita el sobreajuste."
      ],
      "metadata": {
        "id": "IvysId8XKS4r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AqUrk759JjW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}